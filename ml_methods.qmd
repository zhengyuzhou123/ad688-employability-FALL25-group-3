---
title: "Machine Learning Models for Geographic and Remote Work Analysis"
subtitle: "KMeans Clustering, Salary Prediction, and Remote Work Classification"
author:
  - name: "Bingrui Qiao"
  - name: "Zhengyu Zhou"
  - name: "Junhao Wang"
    affiliations: "Boston University"
bibliography: references.bib
csl: csl/econometrica.csl
format:
  html:
    toc: true
    number-sections: true
execute:
  echo: true
  eval: true
  freeze: false
  error: false
  cache: false
  enabled: !expr (os.getenv("CI", "false") == "true")
jupyter: python3
---
# Classification: Remote vs Non-Remote Jobs
```{python}
#| echo: false
#| output: false
import sys, subprocess

for pkg in ["gdown", "pandas", "matplotlib", "missingno", "pyarrow", "scikit-learn"]:
    subprocess.run([sys.executable, "-m", "pip", "install", pkg], check=False)
```
```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix,
    accuracy_score,
    classification_report
)

# 1. Load the ORIGINAL Lightcast dataset
#    (we do NOT use the cleaned subset here, because it only contains Remote jobs)
raw_path = "data/lightcast_job_postings.csv"
df_raw = pd.read_csv(raw_path, low_memory=False)

# 2. Clean the REMOTE_TYPE_NAME column
df_raw["REMOTE_TYPE_NAME"] = (
    df_raw["REMOTE_TYPE_NAME"]
    .astype(str)
    .str.strip()
)

print("Raw REMOTE_TYPE_NAME distribution (top 10):")
print(df_raw["REMOTE_TYPE_NAME"].value_counts(dropna=False).head(10))

# 3. Create a binary label: IS_REMOTE (1 = Remote-related, 0 = Non-Remote)
df_raw["IS_REMOTE"] = df_raw["REMOTE_TYPE_NAME"].str.contains(
    "remote", case=False, na=False
).astype(int)

print("\nIS_REMOTE value counts:")
print(df_raw["IS_REMOTE"].value_counts())

# If the data still has only one class, stop early to avoid model errors
if df_raw["IS_REMOTE"].nunique() < 2:
    raise ValueError(
        "The dataset currently contains only one class for IS_REMOTE. "
        "Classification is not possible with a single class."
    )

# 4. Select features (structured, geography + industry)
feature_cols = ["NAICS_2022_6_NAME", "STATE_NAME"]

for col in feature_cols:
    df_raw[col] = df_raw[col].astype(str).str.strip()

X = df_raw[feature_cols]
y = df_raw["IS_REMOTE"]   # 0 = Non-Remote, 1 = Remote

# 5. Train/Test split (stratify to keep class balance)
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.3,
    random_state=42,
    stratify=y
)

# 6. Preprocessing + Logistic Regression pipeline
preprocess = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), feature_cols)
    ]
)

clf = Pipeline(steps=[
    ("prep", preprocess),
    ("logreg", LogisticRegression(max_iter=300))
])

# 7. Fit the model
clf.fit(X_train, y_train)

# 8. Predictions and evaluation metrics
y_pred = clf.predict(X_test)

print(f"\nAccuracy (Remote vs Non-Remote): {accuracy_score(y_test, y_pred):.3f}\n")

print("Classification report:\n")
print(classification_report(
    y_test,
    y_pred,
    target_names=["Non-Remote", "Remote"]
))

# 9. Confusion matrix plot (for the report)
cm = confusion_matrix(y_test, y_pred)

fig, ax = plt.subplots(figsize=(6, 6))

# Heatmap
sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    cbar=True,
    cbar_kws={"shrink": 0.8},  
    xticklabels=["Non-Remote", "Remote"],
    yticklabels=["Non-Remote", "Remote"],
    ax=ax
)

# Set the title and coordinate axes
ax.set_title("Remote vs Non-Remote Job Classification", fontsize=16, weight="bold", pad=20)
ax.set_xlabel("Predicted label", fontsize=12)
ax.set_ylabel("True label", fontsize=12)

# Set the colorbar label
cbar = ax.collections[0].colorbar
cbar.set_label("Count", rotation=270, labelpad=15)

# layout
fig.tight_layout()

plt.savefig("figures/remote_confusion_matrix.png", dpi=300, bbox_inches="tight")
plt.show()

```

This classifier can accurately identify most non-remote positions, but has difficulties in handling remote positions: many truly remote positions are wrongly classified as non-remote positions, indicating that merely relying on location and industry characteristics is not sufficient to capture the patterns suitable for remote work.


# Salary Regression: Impact of Geography and Remote Work

In this section, we use a multiple linear regression model to predict job salary based on **geographic location (state)** and **remote work type**. This directly supports our topic of *Geographic and Remote Work Analysis* by quantifying how location and remote flexibility influence pay.

```{python}
import os
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 1. Load cleaned dataset
DATA_PATH = "data/cleaned_lightcast.csv"
df = pd.read_csv(DATA_PATH, low_memory=False)

print(f"Loaded rows: {len(df):,}, columns: {df.shape[1]}")

# 2. Choose columns for the regression model
# Try to find a state column
if "STATE_NAME" in df.columns:
    state_col = "STATE_NAME"
elif "STATE" in df.columns:
    state_col = "STATE"
else:
    raise ValueError("No state column found. Please check your dataset (STATE or STATE_NAME).")

remote_col = "REMOTE_TYPE_NAME"
salary_col = "SALARY"

# 3. Basic cleaning: keep only useful columns and drop missing values
df_reg = df[[salary_col, state_col, remote_col]].copy()

# Clean remote type text
df_reg[remote_col] = (
    df_reg[remote_col]
    .astype(str)
    .str.strip()
    .str.lower()
)

# Filter valid salary
df_reg = df_reg[df_reg[salary_col] > 0].dropna()

print(f"After filtering: {len(df_reg):,} rows")

# Optional: sample to speed up rendering
if len(df_reg) > 20000:
    df_reg = df_reg.sample(n=20000, random_state=42)
    print(f"Sampled to 20,000 rows for faster modeling.")

# 4. Simplify remote type into three buckets
def map_remote(x: str) -> str:
    if "remote" in x:
        return "remote"
    if "hybrid" in x:
        return "hybrid"
    return "onsite"

df_reg["REMOTE_SIMPLE"] = df_reg[remote_col].apply(map_remote)

# 5. One-hot encode categorical variables
model_df = df_reg[[salary_col, state_col, "REMOTE_SIMPLE"]].copy()
model_df = pd.get_dummies(
    model_df,
    columns=[state_col, "REMOTE_SIMPLE"],
    drop_first=True
)

X = model_df.drop(salary_col, axis=1)
y = model_df[salary_col]

print(f"Final feature columns: {X.shape[1]}")

# 6. Train/test split (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 7. Fit multiple linear regression
reg = LinearRegression()
reg.fit(X_train, y_train)

y_pred = reg.predict(X_test)

# 8. Evaluation metrics: RMSE & R²
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:,.2f}")
print(f"R²:   {r2:,.3f}")
```


```{python}
# 9. Coefficients as feature importance
coef_df = (
    pd.DataFrame({
        "feature": X.columns,
        "coefficient": reg.coef_
    })
    .sort_values("coefficient", ascending=False)
)

print(coef_df.head(10))
```

```{python}
# 10. Plot feature importance (top 20 coefficients) with Matplotlib

top_n = 20

#top20
top_coef = pd.concat([
    coef_df.head(top_n),
    coef_df.tail(top_n)
])

plt.figure(figsize=(8, 6))
plt.barh(top_coef["feature"], top_coef["coefficient"])
plt.axvline(0, color="black", linewidth=0.8)
plt.title("Top Positive and Negative Coefficients (Salary Regression)")
plt.xlabel("Coefficient")
plt.ylabel("Feature")
plt.tight_layout()

# save png
plt.savefig("figures/feature_importance.png", dpi=300, bbox_inches="tight")
plt.show()

```

```{python}
# 11. Actual vs Predicted salary scatter plot (Matplotlib)

scatter_df = pd.DataFrame({
    "Actual Salary": y_test,
    "Predicted Salary": y_pred
})

plt.figure(figsize=(6, 6))
plt.scatter(
    scatter_df["Actual Salary"],
    scatter_df["Predicted Salary"],
    alpha=0.4
)

# drave
min_val = min(scatter_df["Actual Salary"].min(), scatter_df["Predicted Salary"].min())
max_val = max(scatter_df["Actual Salary"].max(), scatter_df["Predicted Salary"].max())
plt.plot([min_val, max_val], [min_val, max_val], linestyle="--", linewidth=1)

plt.title("Actual vs Predicted Salary")
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.tight_layout()

# save PNG
plt.savefig("figures/actual_vs_predicted.png", dpi=300, bbox_inches="tight")
plt.show()

```